Run ID,Name,Source Type,Source Name,User,Status,memory,model,model__C,model__activation,model__alpha,model__batch_size,model__beta_1,model__beta_2,model__bootstrap,model__ccp_alpha,model__class_prior,model__class_weight,model__criterion,model__dual,model__early_stopping,model__epsilon,model__fit_intercept,model__fit_prior,model__hidden_layer_sizes,model__intercept_scaling,model__l1_ratio,model__learning_rate,model__learning_rate_init,model__loss,model__max_depth,model__max_features,model__max_fun,model__max_iter,model__max_leaf_nodes,model__max_samples,model__min_impurity_decrease,model__min_impurity_split,model__min_samples_leaf,model__min_samples_split,model__min_weight_fraction_leaf,model__momentum,model__multi_class,model__n_estimators,model__n_iter_no_change,model__n_jobs,model__nesterovs_momentum,model__oob_score,model__penalty,model__power_t,model__random_state,model__shuffle,model__solver,model__splitter,model__tol,model__validation_fraction,model__verbose,model__warm_start,preprocessor,preprocessor__normalization,preprocessor__stopwords,steps,training_size,vect,vect__analyzer,vect__binary,vect__decode_error,vect__dtype,vect__encoding,vect__input,vect__lowercase,vect__max_df,vect__max_features,vect__min_df,vect__ngram_range,vect__norm,vect__preprocessor,vect__smooth_idf,vect__stop_words,vect__strip_accents,vect__sublinear_tf,vect__token_pattern,vect__tokenizer,vect__use_idf,vect__vocabulary,verbose,fit_time_mean,fit_time_std,predict_time_mean,predict_time_std,train_accuracy_score_mean,train_accuracy_score_std,train_f1_score_mean,train_f1_score_std,train_roc_auc_score_mean,train_roc_auc_score_std,valid_accuracy_score_mean,valid_accuracy_score_std,valid_f1_score_mean,valid_f1_score_std,valid_roc_auc_score_mean,valid_roc_auc_score_std
1004cf38e8634ebeaf1734e0963226fe,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/validation.py,gonthierlucas,FINISHED,None,MLPClassifier(),,relu,0.0001,auto,0.9,0.999,,,,,,,False,1e-08,,,"(100,)",,,constant,0.001,,,,15000,200,,,,,,,,0.9,,,10,,True,,,0.5,None,True,adam,,0.0001,0.1,False,False,"TextPreprocessor(normalization=1,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",1,"{'of', 'it', 'hasn', 'until', 'where', 'up', 'those', 'some', 'by', 'yours', 'then', 'am', 'in', 'nor', ""won't"", 'him', 'once', 'not', 'y', 'shouldn', 'just', 'you', 'after', 'each', 'off', 'both', 'more', 'aren', ""weren't"", 'our', 'don', ""shan't"", 'into', 'me', 'yourselves', 'won', 'down', 'no', 'hadn', 'if', ""shouldn't"", 'ma', ""it's"", 'was', ""needn't"", 'between', 'how', ""she's"", ""that'll"", 'they', ""didn't"", 'ain', 'what', 'from', ""aren't"", 'mightn', 'its', 'doing', 'out', 'because', 'been', 'as', ""doesn't"", ""wasn't"", 'we', 'had', 'but', 'here', 'd', 'before', 'do', ""you'd"", 'is', 'there', ""couldn't"", 'that', ""mustn't"", 'itself', ""don't"", 'couldn', 'the', 'your', 'yourself', 'his', 'have', ""isn't"", 'when', 'these', 'under', 'on', 'my', 'further', 'themselves', 'why', 'too', 'theirs', 'whom', ""hasn't"", 'mustn', 'against', 'most', 'so', 'own', 'didn', 'and', 'wouldn', 'are', 'while', 'wasn', 'same', 'their', 'll', 'being', 't', 'should', ""you'll"", 'o', 'she', 'isn', 'ours', ""you're"", 've', 'a', 'can', 'with', 'other', 'ourselves', ""hadn't"", 'over', ""mightn't"", 'above', 'has', 'any', 'through', 'at', 'did', 'he', 'now', 'hers', 'herself', 'below', 'i', 'an', 'all', 'doesn', 'them', ""haven't"", 'for', 'which', 'were', 'about', 'her', 'does', 'needn', 'himself', 'few', 's', 'this', 'who', ""wouldn't"", 'very', 'm', 'such', 'again', 'be', 're', ""should've"", 'myself', 'weren', 'only', 'haven', 'or', 'having', 'to', 'during', 'will', 'shan', ""you've"", 'than'}","[('preprocessor', TextPreprocessor(normalization=1,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', TfidfVectorizer()), ('model', MLPClassifier())]",32000,TfidfVectorizer(),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,None,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,629.0425918579101,60.42015433234007,4.609760379791259,0.22150062948191868,0.9998687499999999,0.0001783167827210904,0.9998684734409771,0.00017870194453144817,0.9998688782281239,0.00017812638666808513,0.8829750000000001,0.004346981711486724,0.8832581206498201,0.0044795262997516195,0.8830093767095555,0.00435911509775596
045810543135408cae4464f1a474ff9b,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/validation.py,gonthierlucas,FINISHED,None,LinearSVC(),1.0,,,,,,,,,None,,True,,,True,,,1,,,,squared_hinge,,,,1000,,,,,,,,,ovr,,,,,,l2,,None,,,,0.0001,,0,,"TextPreprocessor(normalization=1,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",1,"{'of', 'it', 'hasn', 'until', 'where', 'up', 'those', 'some', 'by', 'yours', 'then', 'am', 'in', 'nor', ""won't"", 'him', 'once', 'not', 'y', 'shouldn', 'just', 'you', 'after', 'each', 'off', 'both', 'more', 'aren', ""weren't"", 'our', 'don', ""shan't"", 'into', 'me', 'yourselves', 'won', 'down', 'no', 'hadn', 'if', ""shouldn't"", 'ma', ""it's"", 'was', ""needn't"", 'between', 'how', ""she's"", ""that'll"", 'they', ""didn't"", 'ain', 'what', 'from', ""aren't"", 'mightn', 'its', 'doing', 'out', 'because', 'been', 'as', ""doesn't"", ""wasn't"", 'we', 'had', 'but', 'here', 'd', 'before', 'do', ""you'd"", 'is', 'there', ""couldn't"", 'that', ""mustn't"", 'itself', ""don't"", 'couldn', 'the', 'your', 'yourself', 'his', 'have', ""isn't"", 'when', 'these', 'under', 'on', 'my', 'further', 'themselves', 'why', 'too', 'theirs', 'whom', ""hasn't"", 'mustn', 'against', 'most', 'so', 'own', 'didn', 'and', 'wouldn', 'are', 'while', 'wasn', 'same', 'their', 'll', 'being', 't', 'should', ""you'll"", 'o', 'she', 'isn', 'ours', ""you're"", 've', 'a', 'can', 'with', 'other', 'ourselves', ""hadn't"", 'over', ""mightn't"", 'above', 'has', 'any', 'through', 'at', 'did', 'he', 'now', 'hers', 'herself', 'below', 'i', 'an', 'all', 'doesn', 'them', ""haven't"", 'for', 'which', 'were', 'about', 'her', 'does', 'needn', 'himself', 'few', 's', 'this', 'who', ""wouldn't"", 'very', 'm', 'such', 'again', 'be', 're', ""should've"", 'myself', 'weren', 'only', 'haven', 'or', 'having', 'to', 'during', 'will', 'shan', ""you've"", 'than'}","[('preprocessor', TextPreprocessor(normalization=1,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', TfidfVectorizer()), ('model', LinearSVC())]",32000,TfidfVectorizer(),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,None,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,18.635826969146727,0.27072020210958525,4.391564655303955,0.061642447321915914,0.9920562500000001,0.00013317047345415446,0.992042505395397,0.00013141414340008415,0.9920563014634304,0.000133384811884962,0.8942249999999999,0.00268956316155614,0.8950003707348152,0.0028208231058690723,0.8943589750080247,0.0027377925019461567
408148866e4d4c9b96952057f7920a89,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/validation.py,gonthierlucas,FINISHED,None,RandomForestClassifier(max_depth=12),,,,,,,True,0.0,,None,gini,,,,,,,,,,,,12,auto,,,None,None,0.0,None,1,2,0.0,,,100,,None,,False,,,None,,,,,,0,False,"TextPreprocessor(normalization=1,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",1,"{'of', 'it', 'hasn', 'until', 'where', 'up', 'those', 'some', 'by', 'yours', 'then', 'am', 'in', 'nor', ""won't"", 'him', 'once', 'not', 'y', 'shouldn', 'just', 'you', 'after', 'each', 'off', 'both', 'more', 'aren', ""weren't"", 'our', 'don', ""shan't"", 'into', 'me', 'yourselves', 'won', 'down', 'no', 'hadn', 'if', ""shouldn't"", 'ma', ""it's"", 'was', ""needn't"", 'between', 'how', ""she's"", ""that'll"", 'they', ""didn't"", 'ain', 'what', 'from', ""aren't"", 'mightn', 'its', 'doing', 'out', 'because', 'been', 'as', ""doesn't"", ""wasn't"", 'we', 'had', 'but', 'here', 'd', 'before', 'do', ""you'd"", 'is', 'there', ""couldn't"", 'that', ""mustn't"", 'itself', ""don't"", 'couldn', 'the', 'your', 'yourself', 'his', 'have', ""isn't"", 'when', 'these', 'under', 'on', 'my', 'further', 'themselves', 'why', 'too', 'theirs', 'whom', ""hasn't"", 'mustn', 'against', 'most', 'so', 'own', 'didn', 'and', 'wouldn', 'are', 'while', 'wasn', 'same', 'their', 'll', 'being', 't', 'should', ""you'll"", 'o', 'she', 'isn', 'ours', ""you're"", 've', 'a', 'can', 'with', 'other', 'ourselves', ""hadn't"", 'over', ""mightn't"", 'above', 'has', 'any', 'through', 'at', 'did', 'he', 'now', 'hers', 'herself', 'below', 'i', 'an', 'all', 'doesn', 'them', ""haven't"", 'for', 'which', 'were', 'about', 'her', 'does', 'needn', 'himself', 'few', 's', 'this', 'who', ""wouldn't"", 'very', 'm', 'such', 'again', 'be', 're', ""should've"", 'myself', 'weren', 'only', 'haven', 'or', 'having', 'to', 'during', 'will', 'shan', ""you've"", 'than'}","[('preprocessor', TextPreprocessor(normalization=1,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', TfidfVectorizer()), ('model', RandomForestClassifier(max_depth=12))]",32000,TfidfVectorizer(),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,None,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,20.00426697731018,0.33821878251468446,4.5451196193695065,0.1278367106311111,0.8787874999999999,0.001382140550016519,0.8818985176249935,0.0018436783916668778,0.8800235626834562,0.0017078659321833416,0.829775,0.00607782855960908,0.8330368577969816,0.0062518196935051696,0.8304301688014932,0.006215350252768379
0ed06a7d4af647318741d6111d099ec5,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/validation.py,gonthierlucas,FINISHED,None,MultinomialNB(),,,1.0,,,,,,None,,,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"TextPreprocessor(normalization=1,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",1,"{'of', 'it', 'hasn', 'until', 'where', 'up', 'those', 'some', 'by', 'yours', 'then', 'am', 'in', 'nor', ""won't"", 'him', 'once', 'not', 'y', 'shouldn', 'just', 'you', 'after', 'each', 'off', 'both', 'more', 'aren', ""weren't"", 'our', 'don', ""shan't"", 'into', 'me', 'yourselves', 'won', 'down', 'no', 'hadn', 'if', ""shouldn't"", 'ma', ""it's"", 'was', ""needn't"", 'between', 'how', ""she's"", ""that'll"", 'they', ""didn't"", 'ain', 'what', 'from', ""aren't"", 'mightn', 'its', 'doing', 'out', 'because', 'been', 'as', ""doesn't"", ""wasn't"", 'we', 'had', 'but', 'here', 'd', 'before', 'do', ""you'd"", 'is', 'there', ""couldn't"", 'that', ""mustn't"", 'itself', ""don't"", 'couldn', 'the', 'your', 'yourself', 'his', 'have', ""isn't"", 'when', 'these', 'under', 'on', 'my', 'further', 'themselves', 'why', 'too', 'theirs', 'whom', ""hasn't"", 'mustn', 'against', 'most', 'so', 'own', 'didn', 'and', 'wouldn', 'are', 'while', 'wasn', 'same', 'their', 'll', 'being', 't', 'should', ""you'll"", 'o', 'she', 'isn', 'ours', ""you're"", 've', 'a', 'can', 'with', 'other', 'ourselves', ""hadn't"", 'over', ""mightn't"", 'above', 'has', 'any', 'through', 'at', 'did', 'he', 'now', 'hers', 'herself', 'below', 'i', 'an', 'all', 'doesn', 'them', ""haven't"", 'for', 'which', 'were', 'about', 'her', 'does', 'needn', 'himself', 'few', 's', 'this', 'who', ""wouldn't"", 'very', 'm', 'such', 'again', 'be', 're', ""should've"", 'myself', 'weren', 'only', 'haven', 'or', 'having', 'to', 'during', 'will', 'shan', ""you've"", 'than'}","[('preprocessor', TextPreprocessor(normalization=1,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', TfidfVectorizer()), ('model', MultinomialNB())]",32000,TfidfVectorizer(),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,None,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,18.601721143722536,0.42578492381013483,4.376116847991943,0.08678538426314222,0.9176624999999999,0.0006541334917277761,0.9161945828826145,0.0006991858897018284,0.9180880169312612,0.0006343827769336417,0.8641250000000001,0.0036580390921913436,0.8612846914415112,0.003970877450789475,0.8646457511728907,0.003574455241718092
c877b3e4434b4f9db98894df63a30935,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/validation.py,gonthierlucas,FINISHED,None,DecisionTreeClassifier(max_depth=12),,,,,,,,0.0,,None,gini,,,,,,,,,,,,12,None,,,None,,0.0,None,1,2,0.0,,,,,,,,,,None,,,best,,,,,"TextPreprocessor(normalization=1,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",1,"{'of', 'it', 'hasn', 'until', 'where', 'up', 'those', 'some', 'by', 'yours', 'then', 'am', 'in', 'nor', ""won't"", 'him', 'once', 'not', 'y', 'shouldn', 'just', 'you', 'after', 'each', 'off', 'both', 'more', 'aren', ""weren't"", 'our', 'don', ""shan't"", 'into', 'me', 'yourselves', 'won', 'down', 'no', 'hadn', 'if', ""shouldn't"", 'ma', ""it's"", 'was', ""needn't"", 'between', 'how', ""she's"", ""that'll"", 'they', ""didn't"", 'ain', 'what', 'from', ""aren't"", 'mightn', 'its', 'doing', 'out', 'because', 'been', 'as', ""doesn't"", ""wasn't"", 'we', 'had', 'but', 'here', 'd', 'before', 'do', ""you'd"", 'is', 'there', ""couldn't"", 'that', ""mustn't"", 'itself', ""don't"", 'couldn', 'the', 'your', 'yourself', 'his', 'have', ""isn't"", 'when', 'these', 'under', 'on', 'my', 'further', 'themselves', 'why', 'too', 'theirs', 'whom', ""hasn't"", 'mustn', 'against', 'most', 'so', 'own', 'didn', 'and', 'wouldn', 'are', 'while', 'wasn', 'same', 'their', 'll', 'being', 't', 'should', ""you'll"", 'o', 'she', 'isn', 'ours', ""you're"", 've', 'a', 'can', 'with', 'other', 'ourselves', ""hadn't"", 'over', ""mightn't"", 'above', 'has', 'any', 'through', 'at', 'did', 'he', 'now', 'hers', 'herself', 'below', 'i', 'an', 'all', 'doesn', 'them', ""haven't"", 'for', 'which', 'were', 'about', 'her', 'does', 'needn', 'himself', 'few', 's', 'this', 'who', ""wouldn't"", 'very', 'm', 'such', 'again', 'be', 're', ""should've"", 'myself', 'weren', 'only', 'haven', 'or', 'having', 'to', 'during', 'will', 'shan', ""you've"", 'than'}","[('preprocessor', TextPreprocessor(normalization=1,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', TfidfVectorizer()), ('model', DecisionTreeClassifier(max_depth=12))]",32000,TfidfVectorizer(),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,None,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,24.586769151687623,1.0158422337204989,4.47529444694519,0.177978123245502,0.7782875,0.003504539466891482,0.8003827345291322,0.0022777449769354266,0.793145712285158,0.0023714619216640377,0.732925,0.002803569153775226,0.7593270764931068,0.001638375123388635,0.745300355262118,0.0019274506223940903
bb4c336c5bf1459981b68811faa28b87,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/validation.py,gonthierlucas,FINISHED,None,LogisticRegression(max_iter=500),1.0,,,,,,,,,None,,False,,,True,,,1,None,,,,,,,500,,,,,,,,,auto,,,None,,,l2,,None,,lbfgs,,0.0001,,0,False,"TextPreprocessor(normalization=1,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",1,"{'of', 'it', 'hasn', 'until', 'where', 'up', 'those', 'some', 'by', 'yours', 'then', 'am', 'in', 'nor', ""won't"", 'him', 'once', 'not', 'y', 'shouldn', 'just', 'you', 'after', 'each', 'off', 'both', 'more', 'aren', ""weren't"", 'our', 'don', ""shan't"", 'into', 'me', 'yourselves', 'won', 'down', 'no', 'hadn', 'if', ""shouldn't"", 'ma', ""it's"", 'was', ""needn't"", 'between', 'how', ""she's"", ""that'll"", 'they', ""didn't"", 'ain', 'what', 'from', ""aren't"", 'mightn', 'its', 'doing', 'out', 'because', 'been', 'as', ""doesn't"", ""wasn't"", 'we', 'had', 'but', 'here', 'd', 'before', 'do', ""you'd"", 'is', 'there', ""couldn't"", 'that', ""mustn't"", 'itself', ""don't"", 'couldn', 'the', 'your', 'yourself', 'his', 'have', ""isn't"", 'when', 'these', 'under', 'on', 'my', 'further', 'themselves', 'why', 'too', 'theirs', 'whom', ""hasn't"", 'mustn', 'against', 'most', 'so', 'own', 'didn', 'and', 'wouldn', 'are', 'while', 'wasn', 'same', 'their', 'll', 'being', 't', 'should', ""you'll"", 'o', 'she', 'isn', 'ours', ""you're"", 've', 'a', 'can', 'with', 'other', 'ourselves', ""hadn't"", 'over', ""mightn't"", 'above', 'has', 'any', 'through', 'at', 'did', 'he', 'now', 'hers', 'herself', 'below', 'i', 'an', 'all', 'doesn', 'them', ""haven't"", 'for', 'which', 'were', 'about', 'her', 'does', 'needn', 'himself', 'few', 's', 'this', 'who', ""wouldn't"", 'very', 'm', 'such', 'again', 'be', 're', ""should've"", 'myself', 'weren', 'only', 'haven', 'or', 'having', 'to', 'during', 'will', 'shan', ""you've"", 'than'}","[('preprocessor', TextPreprocessor(normalization=1,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', TfidfVectorizer()), ('model', LogisticRegression(max_iter=500))]",32000,TfidfVectorizer(),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,None,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,20.152277517318726,0.6499354530537091,4.335394191741943,0.10143557907672862,0.93478125,0.0006228086584176513,0.935140448731946,0.0006546138873988188,0.9348690275812677,0.0006363596178376276,0.8909499999999999,0.0028024542815182313,0.8919902555302774,0.002847624641984659,0.8911547030176742,0.002829076711445892
