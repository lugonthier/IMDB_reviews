Run ID,Name,Source Type,Source Name,User,Status,memory,model,model__C,model__activation,model__alpha,model__batch_size,model__beta_1,model__beta_2,model__bootstrap,model__ccp_alpha,model__class_prior,model__class_weight,model__criterion,model__dual,model__early_stopping,model__epsilon,model__fit_intercept,model__fit_prior,model__hidden_layer_sizes,model__intercept_scaling,model__l1_ratio,model__learning_rate,model__learning_rate_init,model__loss,model__max_depth,model__max_features,model__max_fun,model__max_iter,model__max_leaf_nodes,model__max_samples,model__min_impurity_decrease,model__min_impurity_split,model__min_samples_leaf,model__min_samples_split,model__min_weight_fraction_leaf,model__momentum,model__multi_class,model__n_estimators,model__n_iter_no_change,model__n_jobs,model__nesterovs_momentum,model__oob_score,model__penalty,model__power_t,model__random_state,model__shuffle,model__solver,model__splitter,model__tol,model__validation_fraction,model__verbose,model__warm_start,preprocessor,preprocessor__normalization,preprocessor__stopwords,steps,training_size,vect,vect__analyzer,vect__binary,vect__decode_error,vect__dtype,vect__encoding,vect__input,vect__lowercase,vect__max_df,vect__max_features,vect__min_df,vect__ngram_range,vect__norm,vect__preprocessor,vect__smooth_idf,vect__stop_words,vect__strip_accents,vect__sublinear_tf,vect__token_pattern,vect__tokenizer,vect__use_idf,vect__vocabulary,verbose,fit_time_mean,fit_time_std,predict_time_mean,predict_time_std,train_accuracy_score_mean,train_accuracy_score_std,train_f1_score_mean,train_f1_score_std,train_roc_auc_score_mean,train_roc_auc_score_std,valid_accuracy_score_mean,valid_accuracy_score_std,valid_f1_score_mean,valid_f1_score_std,valid_roc_auc_score_mean,valid_roc_auc_score_std
f4d7d39ddcfc4e98b63387f8c9deecaa,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/validation.py,gonthierlucas,FINISHED,None,MLPClassifier(),,relu,0.0001,auto,0.9,0.999,,,,,,,False,1e-08,,,"(100,)",,,constant,0.001,,,,15000,200,,,,,,,,0.9,,,10,,True,,,0.5,None,True,adam,,0.0001,0.1,False,False,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{'during', 'whom', ""you'll"", 'wouldn', 'there', 'theirs', 'few', 'will', ""won't"", 'these', 'than', 'in', ""didn't"", 'further', 'have', ""mustn't"", 'your', 'not', ""you'd"", ""wasn't"", 'too', 'been', 'off', 'herself', 'as', ""shan't"", 'didn', 'themselves', 'yourself', 'having', 'were', 'won', 'her', 'under', 'y', 'doing', 'doesn', ""don't"", ""doesn't"", 'an', 'how', 'haven', 'or', 'do', 'those', 'over', 'again', 's', 'most', 'now', 'd', 'itself', 'ourselves', 'after', 'only', 'him', 'such', ""isn't"", 'and', 'our', 'm', 'then', 'ma', 'are', 'who', 'them', 'hers', 'up', 'while', ""it's"", 'very', 'should', ""mightn't"", 'their', 'he', 'yourselves', 'on', 'me', 'can', ""you've"", ""hasn't"", ""needn't"", 'yours', ""you're"", 'below', 'll', 'hadn', 'had', 'when', 'with', 'each', 'some', 'why', 'by', 'between', 'ain', 'out', 'because', 'nor', 'if', 'any', ""should've"", 'wasn', 'be', ""wouldn't"", ""she's"", 'down', 'same', 'against', 'at', 'both', 'through', 'which', 'was', 'until', 'mightn', 'before', ""shouldn't"", 'i', 'does', 'ours', 'am', 'that', 'for', 'here', 'needn', 'the', 'hasn', 'above', ""couldn't"", 'it', 'where', 'from', 'they', 'all', 'couldn', 'isn', 't', 'being', ""weren't"", 'his', 'to', 'has', 'myself', 've', 'himself', 'so', 'shouldn', 'we', 'weren', 'she', 'mustn', 'once', ""that'll"", 'other', 'no', 'o', 're', 'aren', 'its', 'what', 'but', 'you', 'is', 'more', 'don', 'of', 'into', 'this', 'a', 'own', ""aren't"", ""hadn't"", 'shan', 'about', 'did', 'just', 'my', ""haven't""}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', TfidfVectorizer()), ('model', MLPClassifier())]",32000,TfidfVectorizer(),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,None,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,570.7891315937043,52.18767071607928,16.89240403175354,0.11559964872465617,0.99999375,0.000012500000000015278,0.9999937380631829,0.000012523873634107118,0.9999937382592361,0.000012523481527892955,0.876425,0.004231282311545761,0.8770411545947789,0.004392629069422706,0.8765168642416864,0.004263717108219078
8d7350d6a16b4691946cd18b2199c897,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/validation.py,gonthierlucas,FINISHED,None,LinearSVC(),1.0,,,,,,,,,None,,True,,,True,,,1,,,,squared_hinge,,,,1000,,,,,,,,,ovr,,,,,,l2,,None,,,,0.0001,,0,,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{'during', 'whom', ""you'll"", 'wouldn', 'there', 'theirs', 'few', 'will', ""won't"", 'these', 'than', 'in', ""didn't"", 'further', 'have', ""mustn't"", 'your', 'not', ""you'd"", ""wasn't"", 'too', 'been', 'off', 'herself', 'as', ""shan't"", 'didn', 'themselves', 'yourself', 'having', 'were', 'won', 'her', 'under', 'y', 'doing', 'doesn', ""don't"", ""doesn't"", 'an', 'how', 'haven', 'or', 'do', 'those', 'over', 'again', 's', 'most', 'now', 'd', 'itself', 'ourselves', 'after', 'only', 'him', 'such', ""isn't"", 'and', 'our', 'm', 'then', 'ma', 'are', 'who', 'them', 'hers', 'up', 'while', ""it's"", 'very', 'should', ""mightn't"", 'their', 'he', 'yourselves', 'on', 'me', 'can', ""you've"", ""hasn't"", ""needn't"", 'yours', ""you're"", 'below', 'll', 'hadn', 'had', 'when', 'with', 'each', 'some', 'why', 'by', 'between', 'ain', 'out', 'because', 'nor', 'if', 'any', ""should've"", 'wasn', 'be', ""wouldn't"", ""she's"", 'down', 'same', 'against', 'at', 'both', 'through', 'which', 'was', 'until', 'mightn', 'before', ""shouldn't"", 'i', 'does', 'ours', 'am', 'that', 'for', 'here', 'needn', 'the', 'hasn', 'above', ""couldn't"", 'it', 'where', 'from', 'they', 'all', 'couldn', 'isn', 't', 'being', ""weren't"", 'his', 'to', 'has', 'myself', 've', 'himself', 'so', 'shouldn', 'we', 'weren', 'she', 'mustn', 'once', ""that'll"", 'other', 'no', 'o', 're', 'aren', 'its', 'what', 'but', 'you', 'is', 'more', 'don', 'of', 'into', 'this', 'a', 'own', ""aren't"", ""hadn't"", 'shan', 'about', 'did', 'just', 'my', ""haven't""}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', TfidfVectorizer()), ('model', LinearSVC())]",32000,TfidfVectorizer(),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,None,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,68.67120723724365,0.2685249483976281,16.716738367080687,0.19799001645287637,0.9876624999999999,0.00037364337944087824,0.9876449451091052,0.0003725661636355484,0.9876622688746066,0.0003737166151871449,0.89075,0.0025580754484573016,0.8915407852992573,0.0027811751709737355,0.8908875302577727,0.0026216525174563225
a85e34bb6be744668488819704b7d78c,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/validation.py,gonthierlucas,FINISHED,None,RandomForestClassifier(max_depth=12),,,,,,,True,0.0,,None,gini,,,,,,,,,,,,12,auto,,,None,None,0.0,None,1,2,0.0,,,100,,None,,False,,,None,,,,,,0,False,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{'during', 'whom', ""you'll"", 'wouldn', 'there', 'theirs', 'few', 'will', ""won't"", 'these', 'than', 'in', ""didn't"", 'further', 'have', ""mustn't"", 'your', 'not', ""you'd"", ""wasn't"", 'too', 'been', 'off', 'herself', 'as', ""shan't"", 'didn', 'themselves', 'yourself', 'having', 'were', 'won', 'her', 'under', 'y', 'doing', 'doesn', ""don't"", ""doesn't"", 'an', 'how', 'haven', 'or', 'do', 'those', 'over', 'again', 's', 'most', 'now', 'd', 'itself', 'ourselves', 'after', 'only', 'him', 'such', ""isn't"", 'and', 'our', 'm', 'then', 'ma', 'are', 'who', 'them', 'hers', 'up', 'while', ""it's"", 'very', 'should', ""mightn't"", 'their', 'he', 'yourselves', 'on', 'me', 'can', ""you've"", ""hasn't"", ""needn't"", 'yours', ""you're"", 'below', 'll', 'hadn', 'had', 'when', 'with', 'each', 'some', 'why', 'by', 'between', 'ain', 'out', 'because', 'nor', 'if', 'any', ""should've"", 'wasn', 'be', ""wouldn't"", ""she's"", 'down', 'same', 'against', 'at', 'both', 'through', 'which', 'was', 'until', 'mightn', 'before', ""shouldn't"", 'i', 'does', 'ours', 'am', 'that', 'for', 'here', 'needn', 'the', 'hasn', 'above', ""couldn't"", 'it', 'where', 'from', 'they', 'all', 'couldn', 'isn', 't', 'being', ""weren't"", 'his', 'to', 'has', 'myself', 've', 'himself', 'so', 'shouldn', 'we', 'weren', 'she', 'mustn', 'once', ""that'll"", 'other', 'no', 'o', 're', 'aren', 'its', 'what', 'but', 'you', 'is', 'more', 'don', 'of', 'into', 'this', 'a', 'own', ""aren't"", ""hadn't"", 'shan', 'about', 'did', 'just', 'my', ""haven't""}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', TfidfVectorizer()), ('model', RandomForestClassifier(max_depth=12))]",32000,TfidfVectorizer(),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,None,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,69.8096158027649,0.20944918355493114,16.823227071762084,0.0789607273579188,0.878925,0.0035357880133005597,0.8826253161351578,0.0029423031420834317,0.8806239359752979,0.003106538837886946,0.82915,0.004599864128428142,0.8336540013790522,0.0037571331792168585,0.8303366088626098,0.004260780224667534
78b4e543325a4ad5851465d20daca8af,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/validation.py,gonthierlucas,FINISHED,None,MultinomialNB(),,,1.0,,,,,,None,,,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{'during', 'whom', ""you'll"", 'wouldn', 'there', 'theirs', 'few', 'will', ""won't"", 'these', 'than', 'in', ""didn't"", 'further', 'have', ""mustn't"", 'your', 'not', ""you'd"", ""wasn't"", 'too', 'been', 'off', 'herself', 'as', ""shan't"", 'didn', 'themselves', 'yourself', 'having', 'were', 'won', 'her', 'under', 'y', 'doing', 'doesn', ""don't"", ""doesn't"", 'an', 'how', 'haven', 'or', 'do', 'those', 'over', 'again', 's', 'most', 'now', 'd', 'itself', 'ourselves', 'after', 'only', 'him', 'such', ""isn't"", 'and', 'our', 'm', 'then', 'ma', 'are', 'who', 'them', 'hers', 'up', 'while', ""it's"", 'very', 'should', ""mightn't"", 'their', 'he', 'yourselves', 'on', 'me', 'can', ""you've"", ""hasn't"", ""needn't"", 'yours', ""you're"", 'below', 'll', 'hadn', 'had', 'when', 'with', 'each', 'some', 'why', 'by', 'between', 'ain', 'out', 'because', 'nor', 'if', 'any', ""should've"", 'wasn', 'be', ""wouldn't"", ""she's"", 'down', 'same', 'against', 'at', 'both', 'through', 'which', 'was', 'until', 'mightn', 'before', ""shouldn't"", 'i', 'does', 'ours', 'am', 'that', 'for', 'here', 'needn', 'the', 'hasn', 'above', ""couldn't"", 'it', 'where', 'from', 'they', 'all', 'couldn', 'isn', 't', 'being', ""weren't"", 'his', 'to', 'has', 'myself', 've', 'himself', 'so', 'shouldn', 'we', 'weren', 'she', 'mustn', 'once', ""that'll"", 'other', 'no', 'o', 're', 'aren', 'its', 'what', 'but', 'you', 'is', 'more', 'don', 'of', 'into', 'this', 'a', 'own', ""aren't"", ""hadn't"", 'shan', 'about', 'did', 'just', 'my', ""haven't""}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', TfidfVectorizer()), ('model', MultinomialNB())]",32000,TfidfVectorizer(),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,None,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,68.4171040058136,0.27274949129375003,16.888891839981078,0.15337319332637858,0.9100374999999999,0.0010057257951350505,0.9085327908957053,0.0010291474952115738,0.9104005571008521,0.0010036420733807614,0.85985,0.004641120554348938,0.8570957317851331,0.004816574190202163,0.8603024513982527,0.004618906448718475
de04a312b6c145799e945c667025d148,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/validation.py,gonthierlucas,FINISHED,None,DecisionTreeClassifier(max_depth=12),,,,,,,,0.0,,None,gini,,,,,,,,,,,,12,None,,,None,,0.0,None,1,2,0.0,,,,,,,,,,None,,,best,,,,,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{'during', 'whom', ""you'll"", 'wouldn', 'there', 'theirs', 'few', 'will', ""won't"", 'these', 'than', 'in', ""didn't"", 'further', 'have', ""mustn't"", 'your', 'not', ""you'd"", ""wasn't"", 'too', 'been', 'off', 'herself', 'as', ""shan't"", 'didn', 'themselves', 'yourself', 'having', 'were', 'won', 'her', 'under', 'y', 'doing', 'doesn', ""don't"", ""doesn't"", 'an', 'how', 'haven', 'or', 'do', 'those', 'over', 'again', 's', 'most', 'now', 'd', 'itself', 'ourselves', 'after', 'only', 'him', 'such', ""isn't"", 'and', 'our', 'm', 'then', 'ma', 'are', 'who', 'them', 'hers', 'up', 'while', ""it's"", 'very', 'should', ""mightn't"", 'their', 'he', 'yourselves', 'on', 'me', 'can', ""you've"", ""hasn't"", ""needn't"", 'yours', ""you're"", 'below', 'll', 'hadn', 'had', 'when', 'with', 'each', 'some', 'why', 'by', 'between', 'ain', 'out', 'because', 'nor', 'if', 'any', ""should've"", 'wasn', 'be', ""wouldn't"", ""she's"", 'down', 'same', 'against', 'at', 'both', 'through', 'which', 'was', 'until', 'mightn', 'before', ""shouldn't"", 'i', 'does', 'ours', 'am', 'that', 'for', 'here', 'needn', 'the', 'hasn', 'above', ""couldn't"", 'it', 'where', 'from', 'they', 'all', 'couldn', 'isn', 't', 'being', ""weren't"", 'his', 'to', 'has', 'myself', 've', 'himself', 'so', 'shouldn', 'we', 'weren', 'she', 'mustn', 'once', ""that'll"", 'other', 'no', 'o', 're', 'aren', 'its', 'what', 'but', 'you', 'is', 'more', 'don', 'of', 'into', 'this', 'a', 'own', ""aren't"", ""hadn't"", 'shan', 'about', 'did', 'just', 'my', ""haven't""}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', TfidfVectorizer()), ('model', DecisionTreeClassifier(max_depth=12))]",32000,TfidfVectorizer(),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,None,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,73.49512281417847,0.3245557503669315,16.741674375534057,0.10640244598051884,0.7863687500000001,0.001933200875491219,0.8062931232405937,0.0015725660839012773,0.7995482747520718,0.0019687342629815135,0.733975,0.00411354470013394,0.7585198718849562,0.003985641219788916,0.7445169827312313,0.004480682765694294
43d3e409eaad4aaf89cd8f0ddf64ae05,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/validation.py,gonthierlucas,FINISHED,None,LogisticRegression(max_iter=500),1.0,,,,,,,,,None,,False,,,True,,,1,None,,,,,,,500,,,,,,,,,auto,,,None,,,l2,,None,,lbfgs,,0.0001,,0,False,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{'during', 'whom', ""you'll"", 'wouldn', 'there', 'theirs', 'few', 'will', ""won't"", 'these', 'than', 'in', ""didn't"", 'further', 'have', ""mustn't"", 'your', 'not', ""you'd"", ""wasn't"", 'too', 'been', 'off', 'herself', 'as', ""shan't"", 'didn', 'themselves', 'yourself', 'having', 'were', 'won', 'her', 'under', 'y', 'doing', 'doesn', ""don't"", ""doesn't"", 'an', 'how', 'haven', 'or', 'do', 'those', 'over', 'again', 's', 'most', 'now', 'd', 'itself', 'ourselves', 'after', 'only', 'him', 'such', ""isn't"", 'and', 'our', 'm', 'then', 'ma', 'are', 'who', 'them', 'hers', 'up', 'while', ""it's"", 'very', 'should', ""mightn't"", 'their', 'he', 'yourselves', 'on', 'me', 'can', ""you've"", ""hasn't"", ""needn't"", 'yours', ""you're"", 'below', 'll', 'hadn', 'had', 'when', 'with', 'each', 'some', 'why', 'by', 'between', 'ain', 'out', 'because', 'nor', 'if', 'any', ""should've"", 'wasn', 'be', ""wouldn't"", ""she's"", 'down', 'same', 'against', 'at', 'both', 'through', 'which', 'was', 'until', 'mightn', 'before', ""shouldn't"", 'i', 'does', 'ours', 'am', 'that', 'for', 'here', 'needn', 'the', 'hasn', 'above', ""couldn't"", 'it', 'where', 'from', 'they', 'all', 'couldn', 'isn', 't', 'being', ""weren't"", 'his', 'to', 'has', 'myself', 've', 'himself', 'so', 'shouldn', 'we', 'weren', 'she', 'mustn', 'once', ""that'll"", 'other', 'no', 'o', 're', 'aren', 'its', 'what', 'but', 'you', 'is', 'more', 'don', 'of', 'into', 'this', 'a', 'own', ""aren't"", ""hadn't"", 'shan', 'about', 'did', 'just', 'my', ""haven't""}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', TfidfVectorizer()), ('model', LogisticRegression(max_iter=500))]",32000,TfidfVectorizer(),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,None,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,70.86700057983398,2.028772577213697,16.885363483428954,0.09787249401389204,0.93013125,0.0005963430220938435,0.9305406326033279,0.0005905176563885036,0.930226613868735,0.0005947277260920583,0.8897749999999999,0.0025179356624028403,0.8908225812743185,0.0026061994205482243,0.8899896339620217,0.002535488480559629
