Run ID,Name,Source Type,Source Name,User,Status,memory,model,model__bootstrap,model__ccp_alpha,model__class_weight,model__criterion,model__max_depth,model__max_features,model__max_leaf_nodes,model__max_samples,model__min_impurity_decrease,model__min_impurity_split,model__min_samples_leaf,model__min_samples_split,model__min_weight_fraction_leaf,model__n_estimators,model__n_jobs,model__oob_score,model__random_state,model__verbose,model__warm_start,preprocessor,preprocessor__normalization,preprocessor__stopwords,steps,training_size,vect,vect__max_features,vect__ngram_range,vect__vectorizer,vect__vectorizer__analyzer,vect__vectorizer__binary,vect__vectorizer__decode_error,vect__vectorizer__dtype,vect__vectorizer__encoding,vect__vectorizer__input,vect__vectorizer__lowercase,vect__vectorizer__max_df,vect__vectorizer__max_features,vect__vectorizer__min_df,vect__vectorizer__ngram_range,vect__vectorizer__norm,vect__vectorizer__preprocessor,vect__vectorizer__smooth_idf,vect__vectorizer__stop_words,vect__vectorizer__strip_accents,vect__vectorizer__sublinear_tf,vect__vectorizer__token_pattern,vect__vectorizer__tokenizer,vect__vectorizer__use_idf,vect__vectorizer__vocabulary,verbose,fit_time_mean,fit_time_std,predict_time_mean,predict_time_std,train_accuracy_score_mean,train_accuracy_score_std,train_f1_score_mean,train_f1_score_std,train_roc_auc_score_mean,train_roc_auc_score_std,valid_accuracy_score_mean,valid_accuracy_score_std,valid_f1_score_mean,valid_f1_score_std,valid_roc_auc_score_mean,valid_roc_auc_score_std
907304acf1eb41d0ba428119825312e9,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/size_evaluation.py,gonthierlucas,FINISHED,None,RandomForestClassifier(max_depth=12),True,0.0,None,gini,12,auto,None,None,0.0,None,1,2,0.0,100,None,False,None,0,False,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{""shan't"", 're', 'in', ""you'd"", 'his', 'they', 'doing', 'having', ""weren't"", 'further', 'didn', 'its', ""couldn't"", 'such', 'how', 'under', 'd', 'you', ""don't"", ""aren't"", ""she's"", 'wouldn', 'who', 'should', 'itself', ""haven't"", 'what', 'but', 'that', 'at', ""doesn't"", 'is', 'have', 'me', 'hadn', 'too', 'now', 'him', 'being', 'them', 'shouldn', 'i', 'we', 'any', 'why', 'ma', 'shan', 'a', 'her', 't', 'has', 'm', 'were', 's', 'all', 'which', 'just', 'only', 'ain', 'weren', 'our', 'over', 'was', 'will', 'out', 'from', 'both', 'here', 'not', 'of', ""hasn't"", 'above', 'same', 'during', ""mightn't"", 'my', ""that'll"", 'don', 'himself', 'had', 'into', 'few', 'isn', 'mustn', 'these', 'are', 'until', 'very', 'between', 'their', ""you'll"", ""didn't"", 'on', 'so', 'o', 'by', 'll', 'then', 'once', 'themselves', 'if', 'yours', 'and', 'below', 'after', 'because', 'with', 'myself', 'the', 'can', 'for', ""shouldn't"", 'herself', 'ourselves', ""should've"", ""needn't"", 'does', ""hadn't"", 'before', ""mustn't"", 'wasn', 'other', ""wasn't"", ""wouldn't"", 'he', 'y', ""you've"", 'where', 'yourself', 'to', 'your', 'be', 'again', 'couldn', 'do', 'did', 'no', ""isn't"", 'whom', ""you're"", 'most', 'each', 'mightn', 'own', 'hers', 'or', 'some', 'am', 'more', 'through', 'up', 'against', 'she', 'doesn', 'won', 'about', 'been', 'those', 'theirs', 'ours', 'it', ""it's"", 'haven', 'when', 'down', 'this', ""won't"", 'an', 'needn', 've', 'aren', 'than', 'yourselves', 'hasn', 'as', 'nor', 'off', 'while', 'there'}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', Vectorizer(max_features=64000, vectorizer=TfidfVectorizer(max_features=64000))), ('model', RandomForestClassifier(max_depth=12))]",32000,"Vectorizer(max_features=64000, vectorizer=TfidfVectorizer(max_features=64000))",64000,"(1, 1)",TfidfVectorizer(max_features=64000),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,64000,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,70.55023465156555,0.20669492102716286,16.796808338165285,0.08244269105019221,0.88255,0.0026847078518900196,0.8857912311369537,0.0019985250245278027,0.8839715149530942,0.002154309618185982,0.8310749999999999,0.004300872004605584,0.8347443470085745,0.0039509626913514385,0.8318596823973579,0.00420288715523257
60e4ff11e3e147c0b68a98a7e80a8ed4,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/size_evaluation.py,gonthierlucas,FINISHED,None,RandomForestClassifier(max_depth=12),True,0.0,None,gini,12,auto,None,None,0.0,None,1,2,0.0,100,None,False,None,0,False,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{""shan't"", 're', 'in', ""you'd"", 'his', 'they', 'doing', 'having', ""weren't"", 'further', 'didn', 'its', ""couldn't"", 'such', 'how', 'under', 'd', 'you', ""don't"", ""aren't"", ""she's"", 'wouldn', 'who', 'should', 'itself', ""haven't"", 'what', 'but', 'that', 'at', ""doesn't"", 'is', 'have', 'me', 'hadn', 'too', 'now', 'him', 'being', 'them', 'shouldn', 'i', 'we', 'any', 'why', 'ma', 'shan', 'a', 'her', 't', 'has', 'm', 'were', 's', 'all', 'which', 'just', 'only', 'ain', 'weren', 'our', 'over', 'was', 'will', 'out', 'from', 'both', 'here', 'not', 'of', ""hasn't"", 'above', 'same', 'during', ""mightn't"", 'my', ""that'll"", 'don', 'himself', 'had', 'into', 'few', 'isn', 'mustn', 'these', 'are', 'until', 'very', 'between', 'their', ""you'll"", ""didn't"", 'on', 'so', 'o', 'by', 'll', 'then', 'once', 'themselves', 'if', 'yours', 'and', 'below', 'after', 'because', 'with', 'myself', 'the', 'can', 'for', ""shouldn't"", 'herself', 'ourselves', ""should've"", ""needn't"", 'does', ""hadn't"", 'before', ""mustn't"", 'wasn', 'other', ""wasn't"", ""wouldn't"", 'he', 'y', ""you've"", 'where', 'yourself', 'to', 'your', 'be', 'again', 'couldn', 'do', 'did', 'no', ""isn't"", 'whom', ""you're"", 'most', 'each', 'mightn', 'own', 'hers', 'or', 'some', 'am', 'more', 'through', 'up', 'against', 'she', 'doesn', 'won', 'about', 'been', 'those', 'theirs', 'ours', 'it', ""it's"", 'haven', 'when', 'down', 'this', ""won't"", 'an', 'needn', 've', 'aren', 'than', 'yourselves', 'hasn', 'as', 'nor', 'off', 'while', 'there'}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', Vectorizer(max_features=32000, vectorizer=TfidfVectorizer(max_features=32000))), ('model', RandomForestClassifier(max_depth=12))]",32000,"Vectorizer(max_features=32000, vectorizer=TfidfVectorizer(max_features=32000))",32000,"(1, 1)",TfidfVectorizer(max_features=32000),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,32000,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,70.86559181213379,0.1483999486850632,16.77139344215393,0.09538110986830267,0.8820499999999999,0.004555585513959729,0.8862672648979762,0.0040393455568342685,0.8843592281746696,0.004203131549585151,0.8331500000000001,0.0035438326709933657,0.838474124174352,0.0032932507820398766,0.8347750818658215,0.0034572194085068747
cb2afc0fca4c4bad9ba1ef3b1b64399f,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/size_evaluation.py,gonthierlucas,FINISHED,None,RandomForestClassifier(max_depth=12),True,0.0,None,gini,12,auto,None,None,0.0,None,1,2,0.0,100,None,False,None,0,False,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{""shan't"", 're', 'in', ""you'd"", 'his', 'they', 'doing', 'having', ""weren't"", 'further', 'didn', 'its', ""couldn't"", 'such', 'how', 'under', 'd', 'you', ""don't"", ""aren't"", ""she's"", 'wouldn', 'who', 'should', 'itself', ""haven't"", 'what', 'but', 'that', 'at', ""doesn't"", 'is', 'have', 'me', 'hadn', 'too', 'now', 'him', 'being', 'them', 'shouldn', 'i', 'we', 'any', 'why', 'ma', 'shan', 'a', 'her', 't', 'has', 'm', 'were', 's', 'all', 'which', 'just', 'only', 'ain', 'weren', 'our', 'over', 'was', 'will', 'out', 'from', 'both', 'here', 'not', 'of', ""hasn't"", 'above', 'same', 'during', ""mightn't"", 'my', ""that'll"", 'don', 'himself', 'had', 'into', 'few', 'isn', 'mustn', 'these', 'are', 'until', 'very', 'between', 'their', ""you'll"", ""didn't"", 'on', 'so', 'o', 'by', 'll', 'then', 'once', 'themselves', 'if', 'yours', 'and', 'below', 'after', 'because', 'with', 'myself', 'the', 'can', 'for', ""shouldn't"", 'herself', 'ourselves', ""should've"", ""needn't"", 'does', ""hadn't"", 'before', ""mustn't"", 'wasn', 'other', ""wasn't"", ""wouldn't"", 'he', 'y', ""you've"", 'where', 'yourself', 'to', 'your', 'be', 'again', 'couldn', 'do', 'did', 'no', ""isn't"", 'whom', ""you're"", 'most', 'each', 'mightn', 'own', 'hers', 'or', 'some', 'am', 'more', 'through', 'up', 'against', 'she', 'doesn', 'won', 'about', 'been', 'those', 'theirs', 'ours', 'it', ""it's"", 'haven', 'when', 'down', 'this', ""won't"", 'an', 'needn', 've', 'aren', 'than', 'yourselves', 'hasn', 'as', 'nor', 'off', 'while', 'there'}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', Vectorizer(max_features=16000, vectorizer=TfidfVectorizer(max_features=16000))), ('model', RandomForestClassifier(max_depth=12))]",32000,"Vectorizer(max_features=16000, vectorizer=TfidfVectorizer(max_features=16000))",16000,"(1, 1)",TfidfVectorizer(max_features=16000),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,16000,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,71.37763981819153,0.2177056267969479,16.76657462120056,0.09506072507671195,0.8800125,0.0025102601956769424,0.8846858556755585,0.002201534696280196,0.8827672486765568,0.0022976306308988936,0.832175,0.006074331238910167,0.837549206520379,0.005751761375449312,0.8338422006545295,0.005978164058186608
3924fb3203dc49059fd2f31e494a283a,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/size_evaluation.py,gonthierlucas,FINISHED,None,RandomForestClassifier(max_depth=12),True,0.0,None,gini,12,auto,None,None,0.0,None,1,2,0.0,100,None,False,None,0,False,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{""shan't"", 're', 'in', ""you'd"", 'his', 'they', 'doing', 'having', ""weren't"", 'further', 'didn', 'its', ""couldn't"", 'such', 'how', 'under', 'd', 'you', ""don't"", ""aren't"", ""she's"", 'wouldn', 'who', 'should', 'itself', ""haven't"", 'what', 'but', 'that', 'at', ""doesn't"", 'is', 'have', 'me', 'hadn', 'too', 'now', 'him', 'being', 'them', 'shouldn', 'i', 'we', 'any', 'why', 'ma', 'shan', 'a', 'her', 't', 'has', 'm', 'were', 's', 'all', 'which', 'just', 'only', 'ain', 'weren', 'our', 'over', 'was', 'will', 'out', 'from', 'both', 'here', 'not', 'of', ""hasn't"", 'above', 'same', 'during', ""mightn't"", 'my', ""that'll"", 'don', 'himself', 'had', 'into', 'few', 'isn', 'mustn', 'these', 'are', 'until', 'very', 'between', 'their', ""you'll"", ""didn't"", 'on', 'so', 'o', 'by', 'll', 'then', 'once', 'themselves', 'if', 'yours', 'and', 'below', 'after', 'because', 'with', 'myself', 'the', 'can', 'for', ""shouldn't"", 'herself', 'ourselves', ""should've"", ""needn't"", 'does', ""hadn't"", 'before', ""mustn't"", 'wasn', 'other', ""wasn't"", ""wouldn't"", 'he', 'y', ""you've"", 'where', 'yourself', 'to', 'your', 'be', 'again', 'couldn', 'do', 'did', 'no', ""isn't"", 'whom', ""you're"", 'most', 'each', 'mightn', 'own', 'hers', 'or', 'some', 'am', 'more', 'through', 'up', 'against', 'she', 'doesn', 'won', 'about', 'been', 'those', 'theirs', 'ours', 'it', ""it's"", 'haven', 'when', 'down', 'this', ""won't"", 'an', 'needn', 've', 'aren', 'than', 'yourselves', 'hasn', 'as', 'nor', 'off', 'while', 'there'}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', Vectorizer(max_features=8000, vectorizer=TfidfVectorizer(max_features=8000))), ('model', RandomForestClassifier(max_depth=12))]",32000,"Vectorizer(max_features=8000, vectorizer=TfidfVectorizer(max_features=8000))",8000,"(1, 1)",TfidfVectorizer(max_features=8000),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,8000,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,72.78205041885376,0.6960401826918483,16.751990604400635,0.08475871960638609,0.8781437499999999,0.002409340547743305,0.8835152759735336,0.0019087976529263849,0.8816285086413499,0.0019036560581502015,0.8297000000000001,0.005986756216850656,0.8362481606636614,0.005316349606073914,0.8320053938972357,0.005723889755687069
75ec1c4c5b1d41f09a4e7c3b83786846,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/size_evaluation.py,gonthierlucas,FINISHED,None,RandomForestClassifier(max_depth=12),True,0.0,None,gini,12,auto,None,None,0.0,None,1,2,0.0,100,None,False,None,0,False,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{""shan't"", 're', 'in', ""you'd"", 'his', 'they', 'doing', 'having', ""weren't"", 'further', 'didn', 'its', ""couldn't"", 'such', 'how', 'under', 'd', 'you', ""don't"", ""aren't"", ""she's"", 'wouldn', 'who', 'should', 'itself', ""haven't"", 'what', 'but', 'that', 'at', ""doesn't"", 'is', 'have', 'me', 'hadn', 'too', 'now', 'him', 'being', 'them', 'shouldn', 'i', 'we', 'any', 'why', 'ma', 'shan', 'a', 'her', 't', 'has', 'm', 'were', 's', 'all', 'which', 'just', 'only', 'ain', 'weren', 'our', 'over', 'was', 'will', 'out', 'from', 'both', 'here', 'not', 'of', ""hasn't"", 'above', 'same', 'during', ""mightn't"", 'my', ""that'll"", 'don', 'himself', 'had', 'into', 'few', 'isn', 'mustn', 'these', 'are', 'until', 'very', 'between', 'their', ""you'll"", ""didn't"", 'on', 'so', 'o', 'by', 'll', 'then', 'once', 'themselves', 'if', 'yours', 'and', 'below', 'after', 'because', 'with', 'myself', 'the', 'can', 'for', ""shouldn't"", 'herself', 'ourselves', ""should've"", ""needn't"", 'does', ""hadn't"", 'before', ""mustn't"", 'wasn', 'other', ""wasn't"", ""wouldn't"", 'he', 'y', ""you've"", 'where', 'yourself', 'to', 'your', 'be', 'again', 'couldn', 'do', 'did', 'no', ""isn't"", 'whom', ""you're"", 'most', 'each', 'mightn', 'own', 'hers', 'or', 'some', 'am', 'more', 'through', 'up', 'against', 'she', 'doesn', 'won', 'about', 'been', 'those', 'theirs', 'ours', 'it', ""it's"", 'haven', 'when', 'down', 'this', ""won't"", 'an', 'needn', 've', 'aren', 'than', 'yourselves', 'hasn', 'as', 'nor', 'off', 'while', 'there'}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', Vectorizer(max_features=4000, vectorizer=TfidfVectorizer(max_features=4000))), ('model', RandomForestClassifier(max_depth=12))]",32000,"Vectorizer(max_features=4000, vectorizer=TfidfVectorizer(max_features=4000))",4000,"(1, 1)",TfidfVectorizer(max_features=4000),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,4000,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,73.30115323066711,0.27884579853736213,17.03883957862854,0.5867478843344947,0.8770312499999999,0.0020304325278127284,0.8827300075631687,0.0015454741191886973,0.8809090026780382,0.0015691363422416576,0.82585,0.0061193341141009775,0.8327707459895988,0.005165544451782677,0.828296097318612,0.0056555119007665735
d68cbd43111d4ea48ee5d0789ff3af11,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/size_evaluation.py,gonthierlucas,FINISHED,None,RandomForestClassifier(max_depth=12),True,0.0,None,gini,12,auto,None,None,0.0,None,1,2,0.0,100,None,False,None,0,False,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{""shan't"", 're', 'in', ""you'd"", 'his', 'they', 'doing', 'having', ""weren't"", 'further', 'didn', 'its', ""couldn't"", 'such', 'how', 'under', 'd', 'you', ""don't"", ""aren't"", ""she's"", 'wouldn', 'who', 'should', 'itself', ""haven't"", 'what', 'but', 'that', 'at', ""doesn't"", 'is', 'have', 'me', 'hadn', 'too', 'now', 'him', 'being', 'them', 'shouldn', 'i', 'we', 'any', 'why', 'ma', 'shan', 'a', 'her', 't', 'has', 'm', 'were', 's', 'all', 'which', 'just', 'only', 'ain', 'weren', 'our', 'over', 'was', 'will', 'out', 'from', 'both', 'here', 'not', 'of', ""hasn't"", 'above', 'same', 'during', ""mightn't"", 'my', ""that'll"", 'don', 'himself', 'had', 'into', 'few', 'isn', 'mustn', 'these', 'are', 'until', 'very', 'between', 'their', ""you'll"", ""didn't"", 'on', 'so', 'o', 'by', 'll', 'then', 'once', 'themselves', 'if', 'yours', 'and', 'below', 'after', 'because', 'with', 'myself', 'the', 'can', 'for', ""shouldn't"", 'herself', 'ourselves', ""should've"", ""needn't"", 'does', ""hadn't"", 'before', ""mustn't"", 'wasn', 'other', ""wasn't"", ""wouldn't"", 'he', 'y', ""you've"", 'where', 'yourself', 'to', 'your', 'be', 'again', 'couldn', 'do', 'did', 'no', ""isn't"", 'whom', ""you're"", 'most', 'each', 'mightn', 'own', 'hers', 'or', 'some', 'am', 'more', 'through', 'up', 'against', 'she', 'doesn', 'won', 'about', 'been', 'those', 'theirs', 'ours', 'it', ""it's"", 'haven', 'when', 'down', 'this', ""won't"", 'an', 'needn', 've', 'aren', 'than', 'yourselves', 'hasn', 'as', 'nor', 'off', 'while', 'there'}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', Vectorizer(max_features=2000, vectorizer=TfidfVectorizer(max_features=2000))), ('model', RandomForestClassifier(max_depth=12))]",32000,"Vectorizer(max_features=2000, vectorizer=TfidfVectorizer(max_features=2000))",2000,"(1, 1)",TfidfVectorizer(max_features=2000),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,2000,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,74.32066245079041,0.1554939560531646,16.70349988937378,0.09119051747732314,0.87105,0.0023644998149714535,0.8774324699930661,0.0023145345621836044,0.8753936094414602,0.002491806261312575,0.8204,0.005220392705534713,0.828056408392911,0.004756292800163395,0.8232018157394692,0.005076462561654768
d33eff1c69ef49b8833e2b9374766ff1,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/size_evaluation.py,gonthierlucas,FINISHED,None,RandomForestClassifier(max_depth=12),True,0.0,None,gini,12,auto,None,None,0.0,None,1,2,0.0,100,None,False,None,0,False,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{""shan't"", 're', 'in', ""you'd"", 'his', 'they', 'doing', 'having', ""weren't"", 'further', 'didn', 'its', ""couldn't"", 'such', 'how', 'under', 'd', 'you', ""don't"", ""aren't"", ""she's"", 'wouldn', 'who', 'should', 'itself', ""haven't"", 'what', 'but', 'that', 'at', ""doesn't"", 'is', 'have', 'me', 'hadn', 'too', 'now', 'him', 'being', 'them', 'shouldn', 'i', 'we', 'any', 'why', 'ma', 'shan', 'a', 'her', 't', 'has', 'm', 'were', 's', 'all', 'which', 'just', 'only', 'ain', 'weren', 'our', 'over', 'was', 'will', 'out', 'from', 'both', 'here', 'not', 'of', ""hasn't"", 'above', 'same', 'during', ""mightn't"", 'my', ""that'll"", 'don', 'himself', 'had', 'into', 'few', 'isn', 'mustn', 'these', 'are', 'until', 'very', 'between', 'their', ""you'll"", ""didn't"", 'on', 'so', 'o', 'by', 'll', 'then', 'once', 'themselves', 'if', 'yours', 'and', 'below', 'after', 'because', 'with', 'myself', 'the', 'can', 'for', ""shouldn't"", 'herself', 'ourselves', ""should've"", ""needn't"", 'does', ""hadn't"", 'before', ""mustn't"", 'wasn', 'other', ""wasn't"", ""wouldn't"", 'he', 'y', ""you've"", 'where', 'yourself', 'to', 'your', 'be', 'again', 'couldn', 'do', 'did', 'no', ""isn't"", 'whom', ""you're"", 'most', 'each', 'mightn', 'own', 'hers', 'or', 'some', 'am', 'more', 'through', 'up', 'against', 'she', 'doesn', 'won', 'about', 'been', 'those', 'theirs', 'ours', 'it', ""it's"", 'haven', 'when', 'down', 'this', ""won't"", 'an', 'needn', 've', 'aren', 'than', 'yourselves', 'hasn', 'as', 'nor', 'off', 'while', 'there'}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', Vectorizer(max_features=1000, vectorizer=TfidfVectorizer(max_features=1000))), ('model', RandomForestClassifier(max_depth=12))]",32000,"Vectorizer(max_features=1000, vectorizer=TfidfVectorizer(max_features=1000))",1000,"(1, 1)",TfidfVectorizer(max_features=1000),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,1000,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,75.90555882453918,0.1908918887447619,16.76524200439453,0.1705939612042526,0.86633125,0.0025329546729067343,0.8732831881186099,0.002434959387337938,0.8710741401057527,0.0026181407031187504,0.81105,0.006251799740874618,0.8191972660487309,0.005711041708820361,0.8138923538941543,0.006078435009127934
a948ff4437b64689bb2326a1e3e81ef3,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/size_evaluation.py,gonthierlucas,FINISHED,None,RandomForestClassifier(max_depth=12),True,0.0,None,gini,12,auto,None,None,0.0,None,1,2,0.0,100,None,False,None,0,False,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{""shan't"", 're', 'in', ""you'd"", 'his', 'they', 'doing', 'having', ""weren't"", 'further', 'didn', 'its', ""couldn't"", 'such', 'how', 'under', 'd', 'you', ""don't"", ""aren't"", ""she's"", 'wouldn', 'who', 'should', 'itself', ""haven't"", 'what', 'but', 'that', 'at', ""doesn't"", 'is', 'have', 'me', 'hadn', 'too', 'now', 'him', 'being', 'them', 'shouldn', 'i', 'we', 'any', 'why', 'ma', 'shan', 'a', 'her', 't', 'has', 'm', 'were', 's', 'all', 'which', 'just', 'only', 'ain', 'weren', 'our', 'over', 'was', 'will', 'out', 'from', 'both', 'here', 'not', 'of', ""hasn't"", 'above', 'same', 'during', ""mightn't"", 'my', ""that'll"", 'don', 'himself', 'had', 'into', 'few', 'isn', 'mustn', 'these', 'are', 'until', 'very', 'between', 'their', ""you'll"", ""didn't"", 'on', 'so', 'o', 'by', 'll', 'then', 'once', 'themselves', 'if', 'yours', 'and', 'below', 'after', 'because', 'with', 'myself', 'the', 'can', 'for', ""shouldn't"", 'herself', 'ourselves', ""should've"", ""needn't"", 'does', ""hadn't"", 'before', ""mustn't"", 'wasn', 'other', ""wasn't"", ""wouldn't"", 'he', 'y', ""you've"", 'where', 'yourself', 'to', 'your', 'be', 'again', 'couldn', 'do', 'did', 'no', ""isn't"", 'whom', ""you're"", 'most', 'each', 'mightn', 'own', 'hers', 'or', 'some', 'am', 'more', 'through', 'up', 'against', 'she', 'doesn', 'won', 'about', 'been', 'those', 'theirs', 'ours', 'it', ""it's"", 'haven', 'when', 'down', 'this', ""won't"", 'an', 'needn', 've', 'aren', 'than', 'yourselves', 'hasn', 'as', 'nor', 'off', 'while', 'there'}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', Vectorizer(max_features=500, vectorizer=TfidfVectorizer(max_features=500))), ('model', RandomForestClassifier(max_depth=12))]",32000,"Vectorizer(max_features=500, vectorizer=TfidfVectorizer(max_features=500))",500,"(1, 1)",TfidfVectorizer(max_features=500),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,500,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,76.70608592033386,0.2736630957661135,16.78166913986206,0.1425964022073646,0.8573375000000001,0.0008273640371686189,0.8655578547159015,0.0008263053968331871,0.8630756039725446,0.0009472031191713081,0.7981,0.005398147830506342,0.8080864946540732,0.005122565045017473,0.8016368271010321,0.005405818056054576
