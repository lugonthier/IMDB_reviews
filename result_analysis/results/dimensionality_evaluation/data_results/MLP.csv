Run ID,Name,Source Type,Source Name,User,Status,memory,model,model__activation,model__alpha,model__batch_size,model__beta_1,model__beta_2,model__early_stopping,model__epsilon,model__hidden_layer_sizes,model__learning_rate,model__learning_rate_init,model__max_fun,model__max_iter,model__momentum,model__n_iter_no_change,model__nesterovs_momentum,model__power_t,model__random_state,model__shuffle,model__solver,model__tol,model__validation_fraction,model__verbose,model__warm_start,preprocessor,preprocessor__normalization,preprocessor__stopwords,steps,training_size,vect,vect__max_features,vect__ngram_range,vect__vectorizer,vect__vectorizer__analyzer,vect__vectorizer__binary,vect__vectorizer__decode_error,vect__vectorizer__dtype,vect__vectorizer__encoding,vect__vectorizer__input,vect__vectorizer__lowercase,vect__vectorizer__max_df,vect__vectorizer__max_features,vect__vectorizer__min_df,vect__vectorizer__ngram_range,vect__vectorizer__norm,vect__vectorizer__preprocessor,vect__vectorizer__smooth_idf,vect__vectorizer__stop_words,vect__vectorizer__strip_accents,vect__vectorizer__sublinear_tf,vect__vectorizer__token_pattern,vect__vectorizer__tokenizer,vect__vectorizer__use_idf,vect__vectorizer__vocabulary,verbose,fit_time_mean,fit_time_std,predict_time_mean,predict_time_std,train_accuracy_score_mean,train_accuracy_score_std,train_f1_score_mean,train_f1_score_std,train_roc_auc_score_mean,train_roc_auc_score_std,valid_accuracy_score_mean,valid_accuracy_score_std,valid_f1_score_mean,valid_f1_score_std,valid_roc_auc_score_mean,valid_roc_auc_score_std
c67b9922f0964536a200faada60a0773,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/size_evaluation.py,gonthierlucas,FINISHED,None,MLPClassifier(),relu,0.0001,auto,0.9,0.999,False,1e-08,"(100,)",constant,0.001,15000,200,0.9,10,True,0.5,None,True,adam,0.0001,0.1,False,False,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{""should've"", 'herself', 'out', 'in', 'doesn', 'this', 'it', 'below', 'but', 'which', 'didn', 'if', 'once', 'you', 'd', ""that'll"", 'o', ""shan't"", 'them', 'is', 'own', 'very', 'hadn', 'won', 'to', ""needn't"", 'itself', 'nor', ""she's"", 'm', 'mustn', 'theirs', 'for', 'from', ""doesn't"", ""aren't"", 'than', 'll', ""weren't"", 'my', ""didn't"", ""hasn't"", 'about', 've', 'the', 'further', 'at', 'am', 'any', 'its', ""don't"", 'himself', ""isn't"", 'are', 'y', 'they', 'why', 'can', 'until', 'have', 'don', 'some', 'yours', 'he', 'did', 'does', 'will', 'above', 'had', 'on', 'against', 'him', 'because', 'up', 'before', 'after', 'such', 'were', 'been', 't', 'so', 'me', 'weren', 'with', 'as', 'should', 'ma', 'yourself', ""wouldn't"", 'having', 'while', 'too', ""wasn't"", ""you're"", 'only', 'mightn', 'we', 'needn', 'over', 'has', 'other', 's', ""haven't"", 'how', 'both', 'no', 'an', 'whom', 'i', 'during', 'down', 'yourselves', 'into', 'off', 'ours', 'through', 'ain', 'isn', 'being', 'do', 'their', 'or', 'more', 'those', 'most', 'haven', 'what', 'doing', 'under', 'each', ""couldn't"", 'her', 'be', 'few', 'shan', 'themselves', 'and', 'there', ""won't"", 'here', 'when', 'between', ""mustn't"", 'wasn', ""shouldn't"", ""hadn't"", 'now', ""you've"", 'hasn', 'myself', ""you'll"", 'she', 'not', 'of', 'hers', 'our', 'ourselves', 'was', ""it's"", 'a', ""you'd"", 'your', 'then', 're', 'again', 'just', 'where', 'same', 'couldn', 'who', 'by', 'wouldn', ""mightn't"", 'these', 'aren', 'that', 'his', 'all', 'shouldn'}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', Vectorizer(max_features=64000, vectorizer=TfidfVectorizer(max_features=64000))), ('model', MLPClassifier())]",32000,"Vectorizer(max_features=64000, vectorizer=TfidfVectorizer(max_features=64000))",64000,"(1, 1)",TfidfVectorizer(max_features=64000),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,64000,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,376.15444712638856,28.85785393687968,16.920644330978394,0.09572656488842958,0.9999625,0.000045927932677198415,0.9999624240651552,0.00004602306833971465,0.9999625306944857,0.00004582076524672971,0.873575,0.004433255011839481,0.8738952257667074,0.004928026224358312,0.8736957154161562,0.004487184677929718
a51eec17bfdc4aff9b9f688568e25597,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/size_evaluation.py,gonthierlucas,FINISHED,None,MLPClassifier(),relu,0.0001,auto,0.9,0.999,False,1e-08,"(100,)",constant,0.001,15000,200,0.9,10,True,0.5,None,True,adam,0.0001,0.1,False,False,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{""should've"", 'herself', 'out', 'in', 'doesn', 'this', 'it', 'below', 'but', 'which', 'didn', 'if', 'once', 'you', 'd', ""that'll"", 'o', ""shan't"", 'them', 'is', 'own', 'very', 'hadn', 'won', 'to', ""needn't"", 'itself', 'nor', ""she's"", 'm', 'mustn', 'theirs', 'for', 'from', ""doesn't"", ""aren't"", 'than', 'll', ""weren't"", 'my', ""didn't"", ""hasn't"", 'about', 've', 'the', 'further', 'at', 'am', 'any', 'its', ""don't"", 'himself', ""isn't"", 'are', 'y', 'they', 'why', 'can', 'until', 'have', 'don', 'some', 'yours', 'he', 'did', 'does', 'will', 'above', 'had', 'on', 'against', 'him', 'because', 'up', 'before', 'after', 'such', 'were', 'been', 't', 'so', 'me', 'weren', 'with', 'as', 'should', 'ma', 'yourself', ""wouldn't"", 'having', 'while', 'too', ""wasn't"", ""you're"", 'only', 'mightn', 'we', 'needn', 'over', 'has', 'other', 's', ""haven't"", 'how', 'both', 'no', 'an', 'whom', 'i', 'during', 'down', 'yourselves', 'into', 'off', 'ours', 'through', 'ain', 'isn', 'being', 'do', 'their', 'or', 'more', 'those', 'most', 'haven', 'what', 'doing', 'under', 'each', ""couldn't"", 'her', 'be', 'few', 'shan', 'themselves', 'and', 'there', ""won't"", 'here', 'when', 'between', ""mustn't"", 'wasn', ""shouldn't"", ""hadn't"", 'now', ""you've"", 'hasn', 'myself', ""you'll"", 'she', 'not', 'of', 'hers', 'our', 'ourselves', 'was', ""it's"", 'a', ""you'd"", 'your', 'then', 're', 'again', 'just', 'where', 'same', 'couldn', 'who', 'by', 'wouldn', ""mightn't"", 'these', 'aren', 'that', 'his', 'all', 'shouldn'}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', Vectorizer(max_features=32000, vectorizer=TfidfVectorizer(max_features=32000))), ('model', MLPClassifier())]",32000,"Vectorizer(max_features=32000, vectorizer=TfidfVectorizer(max_features=32000))",32000,"(1, 1)",TfidfVectorizer(max_features=32000),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,32000,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,236.1494725227356,11.71183626519639,16.893102836608886,0.08873278837222928,0.9998375000000002,0.00015232572008692274,0.9998371731720717,0.00015263165794435828,0.9998376043790007,0.00015228855405438537,0.868225,0.0017128193132960596,0.8688746122339708,0.002470335125083236,0.8683740167522185,0.0018106984784544335
70d097b553bf40538c476899da8cc59a,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/size_evaluation.py,gonthierlucas,FINISHED,None,MLPClassifier(),relu,0.0001,auto,0.9,0.999,False,1e-08,"(100,)",constant,0.001,15000,200,0.9,10,True,0.5,None,True,adam,0.0001,0.1,False,False,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{""should've"", 'herself', 'out', 'in', 'doesn', 'this', 'it', 'below', 'but', 'which', 'didn', 'if', 'once', 'you', 'd', ""that'll"", 'o', ""shan't"", 'them', 'is', 'own', 'very', 'hadn', 'won', 'to', ""needn't"", 'itself', 'nor', ""she's"", 'm', 'mustn', 'theirs', 'for', 'from', ""doesn't"", ""aren't"", 'than', 'll', ""weren't"", 'my', ""didn't"", ""hasn't"", 'about', 've', 'the', 'further', 'at', 'am', 'any', 'its', ""don't"", 'himself', ""isn't"", 'are', 'y', 'they', 'why', 'can', 'until', 'have', 'don', 'some', 'yours', 'he', 'did', 'does', 'will', 'above', 'had', 'on', 'against', 'him', 'because', 'up', 'before', 'after', 'such', 'were', 'been', 't', 'so', 'me', 'weren', 'with', 'as', 'should', 'ma', 'yourself', ""wouldn't"", 'having', 'while', 'too', ""wasn't"", ""you're"", 'only', 'mightn', 'we', 'needn', 'over', 'has', 'other', 's', ""haven't"", 'how', 'both', 'no', 'an', 'whom', 'i', 'during', 'down', 'yourselves', 'into', 'off', 'ours', 'through', 'ain', 'isn', 'being', 'do', 'their', 'or', 'more', 'those', 'most', 'haven', 'what', 'doing', 'under', 'each', ""couldn't"", 'her', 'be', 'few', 'shan', 'themselves', 'and', 'there', ""won't"", 'here', 'when', 'between', ""mustn't"", 'wasn', ""shouldn't"", ""hadn't"", 'now', ""you've"", 'hasn', 'myself', ""you'll"", 'she', 'not', 'of', 'hers', 'our', 'ourselves', 'was', ""it's"", 'a', ""you'd"", 'your', 'then', 're', 'again', 'just', 'where', 'same', 'couldn', 'who', 'by', 'wouldn', ""mightn't"", 'these', 'aren', 'that', 'his', 'all', 'shouldn'}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', Vectorizer(max_features=16000, vectorizer=TfidfVectorizer(max_features=16000))), ('model', MLPClassifier())]",32000,"Vectorizer(max_features=16000, vectorizer=TfidfVectorizer(max_features=16000))",16000,"(1, 1)",TfidfVectorizer(max_features=16000),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,16000,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,153.40529861450196,1.8453078598061923,16.941932201385498,0.07987447340122995,0.9996937500000002,0.0005356071321407226,0.9996928258940538,0.000537301231048442,0.9996947826717271,0.000533580472486833,0.8591749999999999,0.003937480158680157,0.8587741438396487,0.004293754211771023,0.8592993194585565,0.003999084421441448
13ee3363634743dd8f9f6a116b773921,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/size_evaluation.py,gonthierlucas,FINISHED,None,MLPClassifier(),relu,0.0001,auto,0.9,0.999,False,1e-08,"(100,)",constant,0.001,15000,200,0.9,10,True,0.5,None,True,adam,0.0001,0.1,False,False,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{""should've"", 'herself', 'out', 'in', 'doesn', 'this', 'it', 'below', 'but', 'which', 'didn', 'if', 'once', 'you', 'd', ""that'll"", 'o', ""shan't"", 'them', 'is', 'own', 'very', 'hadn', 'won', 'to', ""needn't"", 'itself', 'nor', ""she's"", 'm', 'mustn', 'theirs', 'for', 'from', ""doesn't"", ""aren't"", 'than', 'll', ""weren't"", 'my', ""didn't"", ""hasn't"", 'about', 've', 'the', 'further', 'at', 'am', 'any', 'its', ""don't"", 'himself', ""isn't"", 'are', 'y', 'they', 'why', 'can', 'until', 'have', 'don', 'some', 'yours', 'he', 'did', 'does', 'will', 'above', 'had', 'on', 'against', 'him', 'because', 'up', 'before', 'after', 'such', 'were', 'been', 't', 'so', 'me', 'weren', 'with', 'as', 'should', 'ma', 'yourself', ""wouldn't"", 'having', 'while', 'too', ""wasn't"", ""you're"", 'only', 'mightn', 'we', 'needn', 'over', 'has', 'other', 's', ""haven't"", 'how', 'both', 'no', 'an', 'whom', 'i', 'during', 'down', 'yourselves', 'into', 'off', 'ours', 'through', 'ain', 'isn', 'being', 'do', 'their', 'or', 'more', 'those', 'most', 'haven', 'what', 'doing', 'under', 'each', ""couldn't"", 'her', 'be', 'few', 'shan', 'themselves', 'and', 'there', ""won't"", 'here', 'when', 'between', ""mustn't"", 'wasn', ""shouldn't"", ""hadn't"", 'now', ""you've"", 'hasn', 'myself', ""you'll"", 'she', 'not', 'of', 'hers', 'our', 'ourselves', 'was', ""it's"", 'a', ""you'd"", 'your', 'then', 're', 'again', 'just', 'where', 'same', 'couldn', 'who', 'by', 'wouldn', ""mightn't"", 'these', 'aren', 'that', 'his', 'all', 'shouldn'}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', Vectorizer(max_features=8000, vectorizer=TfidfVectorizer(max_features=8000))), ('model', MLPClassifier())]",32000,"Vectorizer(max_features=8000, vectorizer=TfidfVectorizer(max_features=8000))",8000,"(1, 1)",TfidfVectorizer(max_features=8000),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,8000,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,143.70059552192689,3.2518172452760954,16.996012496948243,0.07324118986704503,0.9999499999999999,0.00004238956239453235,0.9999499064658967,0.000042468209457307944,0.9999499107784271,0.00004246433671852047,0.85145,0.004054781128495085,0.8514590507091286,0.004432932323721344,0.8515030333840453,0.004023023183536426
50446198394640958613ae93df105812,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/size_evaluation.py,gonthierlucas,FINISHED,None,MLPClassifier(),relu,0.0001,auto,0.9,0.999,False,1e-08,"(100,)",constant,0.001,15000,200,0.9,10,True,0.5,None,True,adam,0.0001,0.1,False,False,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{""should've"", 'herself', 'out', 'in', 'doesn', 'this', 'it', 'below', 'but', 'which', 'didn', 'if', 'once', 'you', 'd', ""that'll"", 'o', ""shan't"", 'them', 'is', 'own', 'very', 'hadn', 'won', 'to', ""needn't"", 'itself', 'nor', ""she's"", 'm', 'mustn', 'theirs', 'for', 'from', ""doesn't"", ""aren't"", 'than', 'll', ""weren't"", 'my', ""didn't"", ""hasn't"", 'about', 've', 'the', 'further', 'at', 'am', 'any', 'its', ""don't"", 'himself', ""isn't"", 'are', 'y', 'they', 'why', 'can', 'until', 'have', 'don', 'some', 'yours', 'he', 'did', 'does', 'will', 'above', 'had', 'on', 'against', 'him', 'because', 'up', 'before', 'after', 'such', 'were', 'been', 't', 'so', 'me', 'weren', 'with', 'as', 'should', 'ma', 'yourself', ""wouldn't"", 'having', 'while', 'too', ""wasn't"", ""you're"", 'only', 'mightn', 'we', 'needn', 'over', 'has', 'other', 's', ""haven't"", 'how', 'both', 'no', 'an', 'whom', 'i', 'during', 'down', 'yourselves', 'into', 'off', 'ours', 'through', 'ain', 'isn', 'being', 'do', 'their', 'or', 'more', 'those', 'most', 'haven', 'what', 'doing', 'under', 'each', ""couldn't"", 'her', 'be', 'few', 'shan', 'themselves', 'and', 'there', ""won't"", 'here', 'when', 'between', ""mustn't"", 'wasn', ""shouldn't"", ""hadn't"", 'now', ""you've"", 'hasn', 'myself', ""you'll"", 'she', 'not', 'of', 'hers', 'our', 'ourselves', 'was', ""it's"", 'a', ""you'd"", 'your', 'then', 're', 'again', 'just', 'where', 'same', 'couldn', 'who', 'by', 'wouldn', ""mightn't"", 'these', 'aren', 'that', 'his', 'all', 'shouldn'}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', Vectorizer(max_features=4000, vectorizer=TfidfVectorizer(max_features=4000))), ('model', MLPClassifier())]",32000,"Vectorizer(max_features=4000, vectorizer=TfidfVectorizer(max_features=4000))",4000,"(1, 1)",TfidfVectorizer(max_features=4000),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,4000,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,112.53491659164429,2.5991042208793815,17.174950218200685,0.26272089151092604,0.9999625000000002,0.000030618621784772755,0.9999624295554164,0.000030676139546454005,0.9999624319078328,0.00003067421880634739,0.866725,0.004686016431896078,0.8665817313036998,0.005011123865097295,0.8667497139313817,0.004709536210493493
91cd254aa53b4d0a994d5dfeb06a336e,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/size_evaluation.py,gonthierlucas,FINISHED,None,MLPClassifier(),relu,0.0001,auto,0.9,0.999,False,1e-08,"(100,)",constant,0.001,15000,200,0.9,10,True,0.5,None,True,adam,0.0001,0.1,False,False,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{""should've"", 'herself', 'out', 'in', 'doesn', 'this', 'it', 'below', 'but', 'which', 'didn', 'if', 'once', 'you', 'd', ""that'll"", 'o', ""shan't"", 'them', 'is', 'own', 'very', 'hadn', 'won', 'to', ""needn't"", 'itself', 'nor', ""she's"", 'm', 'mustn', 'theirs', 'for', 'from', ""doesn't"", ""aren't"", 'than', 'll', ""weren't"", 'my', ""didn't"", ""hasn't"", 'about', 've', 'the', 'further', 'at', 'am', 'any', 'its', ""don't"", 'himself', ""isn't"", 'are', 'y', 'they', 'why', 'can', 'until', 'have', 'don', 'some', 'yours', 'he', 'did', 'does', 'will', 'above', 'had', 'on', 'against', 'him', 'because', 'up', 'before', 'after', 'such', 'were', 'been', 't', 'so', 'me', 'weren', 'with', 'as', 'should', 'ma', 'yourself', ""wouldn't"", 'having', 'while', 'too', ""wasn't"", ""you're"", 'only', 'mightn', 'we', 'needn', 'over', 'has', 'other', 's', ""haven't"", 'how', 'both', 'no', 'an', 'whom', 'i', 'during', 'down', 'yourselves', 'into', 'off', 'ours', 'through', 'ain', 'isn', 'being', 'do', 'their', 'or', 'more', 'those', 'most', 'haven', 'what', 'doing', 'under', 'each', ""couldn't"", 'her', 'be', 'few', 'shan', 'themselves', 'and', 'there', ""won't"", 'here', 'when', 'between', ""mustn't"", 'wasn', ""shouldn't"", ""hadn't"", 'now', ""you've"", 'hasn', 'myself', ""you'll"", 'she', 'not', 'of', 'hers', 'our', 'ourselves', 'was', ""it's"", 'a', ""you'd"", 'your', 'then', 're', 'again', 'just', 'where', 'same', 'couldn', 'who', 'by', 'wouldn', ""mightn't"", 'these', 'aren', 'that', 'his', 'all', 'shouldn'}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', Vectorizer(max_features=2000, vectorizer=TfidfVectorizer(max_features=2000))), ('model', MLPClassifier())]",32000,"Vectorizer(max_features=2000, vectorizer=TfidfVectorizer(max_features=2000))",2000,"(1, 1)",TfidfVectorizer(max_features=2000),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,2000,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,100.61997113227844,1.3873294920885573,17.44392442703247,0.3453657055000257,0.99998125,0.000015309310892413574,0.9999812137974058,0.00001533887020353474,0.9999812389935221,0.00001531836144622139,0.8675,0.005355487839590335,0.8674870514532838,0.005931705352509982,0.8675408601437088,0.005376287927274977
c9252286d7724084b51b688724c9c4bc,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/size_evaluation.py,gonthierlucas,FINISHED,None,MLPClassifier(),relu,0.0001,auto,0.9,0.999,False,1e-08,"(100,)",constant,0.001,15000,200,0.9,10,True,0.5,None,True,adam,0.0001,0.1,False,False,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{""should've"", 'herself', 'out', 'in', 'doesn', 'this', 'it', 'below', 'but', 'which', 'didn', 'if', 'once', 'you', 'd', ""that'll"", 'o', ""shan't"", 'them', 'is', 'own', 'very', 'hadn', 'won', 'to', ""needn't"", 'itself', 'nor', ""she's"", 'm', 'mustn', 'theirs', 'for', 'from', ""doesn't"", ""aren't"", 'than', 'll', ""weren't"", 'my', ""didn't"", ""hasn't"", 'about', 've', 'the', 'further', 'at', 'am', 'any', 'its', ""don't"", 'himself', ""isn't"", 'are', 'y', 'they', 'why', 'can', 'until', 'have', 'don', 'some', 'yours', 'he', 'did', 'does', 'will', 'above', 'had', 'on', 'against', 'him', 'because', 'up', 'before', 'after', 'such', 'were', 'been', 't', 'so', 'me', 'weren', 'with', 'as', 'should', 'ma', 'yourself', ""wouldn't"", 'having', 'while', 'too', ""wasn't"", ""you're"", 'only', 'mightn', 'we', 'needn', 'over', 'has', 'other', 's', ""haven't"", 'how', 'both', 'no', 'an', 'whom', 'i', 'during', 'down', 'yourselves', 'into', 'off', 'ours', 'through', 'ain', 'isn', 'being', 'do', 'their', 'or', 'more', 'those', 'most', 'haven', 'what', 'doing', 'under', 'each', ""couldn't"", 'her', 'be', 'few', 'shan', 'themselves', 'and', 'there', ""won't"", 'here', 'when', 'between', ""mustn't"", 'wasn', ""shouldn't"", ""hadn't"", 'now', ""you've"", 'hasn', 'myself', ""you'll"", 'she', 'not', 'of', 'hers', 'our', 'ourselves', 'was', ""it's"", 'a', ""you'd"", 'your', 'then', 're', 'again', 'just', 'where', 'same', 'couldn', 'who', 'by', 'wouldn', ""mightn't"", 'these', 'aren', 'that', 'his', 'all', 'shouldn'}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', Vectorizer(max_features=1000, vectorizer=TfidfVectorizer(max_features=1000))), ('model', MLPClassifier())]",32000,"Vectorizer(max_features=1000, vectorizer=TfidfVectorizer(max_features=1000))",1000,"(1, 1)",TfidfVectorizer(max_features=1000),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,1000,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,96.4835175037384,1.7080115558691273,17.188293266296387,0.239600727872249,1,0,1,0,1,0,0.8543749999999999,0.003788964238416607,0.8549515742501695,0.0037134075736878366,0.8544573278173544,0.0037565796094485445
fdd11888be934731a64f30fa4af85d6c,,LOCAL,/Users/gonthierlucas/Desktop/DS_project/IMDB_reviews/experimentation/size_evaluation.py,gonthierlucas,FINISHED,None,MLPClassifier(),relu,0.0001,auto,0.9,0.999,False,1e-08,"(100,)",constant,0.001,15000,200,0.9,10,True,0.5,None,True,adam,0.0001,0.1,False,False,"TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})",2,"{""should've"", 'herself', 'out', 'in', 'doesn', 'this', 'it', 'below', 'but', 'which', 'didn', 'if', 'once', 'you', 'd', ""that'll"", 'o', ""shan't"", 'them', 'is', 'own', 'very', 'hadn', 'won', 'to', ""needn't"", 'itself', 'nor', ""she's"", 'm', 'mustn', 'theirs', 'for', 'from', ""doesn't"", ""aren't"", 'than', 'll', ""weren't"", 'my', ""didn't"", ""hasn't"", 'about', 've', 'the', 'further', 'at', 'am', 'any', 'its', ""don't"", 'himself', ""isn't"", 'are', 'y', 'they', 'why', 'can', 'until', 'have', 'don', 'some', 'yours', 'he', 'did', 'does', 'will', 'above', 'had', 'on', 'against', 'him', 'because', 'up', 'before', 'after', 'such', 'were', 'been', 't', 'so', 'me', 'weren', 'with', 'as', 'should', 'ma', 'yourself', ""wouldn't"", 'having', 'while', 'too', ""wasn't"", ""you're"", 'only', 'mightn', 'we', 'needn', 'over', 'has', 'other', 's', ""haven't"", 'how', 'both', 'no', 'an', 'whom', 'i', 'during', 'down', 'yourselves', 'into', 'off', 'ours', 'through', 'ain', 'isn', 'being', 'do', 'their', 'or', 'more', 'those', 'most', 'haven', 'what', 'doing', 'under', 'each', ""couldn't"", 'her', 'be', 'few', 'shan', 'themselves', 'and', 'there', ""won't"", 'here', 'when', 'between', ""mustn't"", 'wasn', ""shouldn't"", ""hadn't"", 'now', ""you've"", 'hasn', 'myself', ""you'll"", 'she', 'not', 'of', 'hers', 'our', 'ourselves', 'was', ""it's"", 'a', ""you'd"", 'your', 'then', 're', 'again', 'just', 'where', 'same', 'couldn', 'who', 'by', 'wouldn', ""mightn't"", 'these', 'aren', 'that', 'his', 'all', 'shouldn'}","[('preprocessor', TextPreprocessor(normalization=2,
                 stopwords={'a', 'about', 'above', 'after', 'again', 'against',
                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',
                            'aren', ""aren't"", 'as', 'at', 'be', 'because',
                            'been', 'before', 'being', 'below', 'between',
                            'both', 'but', 'by', 'can', 'couldn', ""couldn't"", ...})), ('vect', Vectorizer(max_features=500, vectorizer=TfidfVectorizer(max_features=500))), ('model', MLPClassifier())]",32000,"Vectorizer(max_features=500, vectorizer=TfidfVectorizer(max_features=500))",500,"(1, 1)",TfidfVectorizer(max_features=500),word,False,strict,<class 'numpy.float64'>,utf-8,content,True,1.0,500,1,"(1, 1)",l2,None,True,None,None,False,(?u)\b\w\w+\b,None,True,None,False,96.6362030506134,1.1720857679868006,17.122185516357423,0.20170699391560915,1,0,1,0,1,0,0.8280749999999999,0.003948575692575757,0.8285392110927535,0.0033165546810811583,0.8282222479623051,0.003890175990386222
